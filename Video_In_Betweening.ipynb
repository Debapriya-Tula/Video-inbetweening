{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Video In Betweening",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOkgYoGWmralxAiaTPMi7Tw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Debapriya-Tula/Video-inbetweening/blob/master/Video_In_Betweening.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4L4gEoGrFBl",
        "colab_type": "code",
        "outputId": "697fe1b7-ede3-4fbc-f6e1-5a4bdbee83a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "! wget --no-check-certificate https://www.crcv.ucf.edu/data/UCF101/UCF101.rar"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-19 16:39:57--  https://www.crcv.ucf.edu/data/UCF101/UCF101.rar\n",
            "Resolving www.crcv.ucf.edu (www.crcv.ucf.edu)... 132.170.214.127\n",
            "Connecting to www.crcv.ucf.edu (www.crcv.ucf.edu)|132.170.214.127|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6932971618 (6.5G) [application/rar]\n",
            "Saving to: ‘UCF101.rar’\n",
            "\n",
            "UCF101.rar          100%[===================>]   6.46G  28.8MB/s    in 2m 26s  \n",
            "\n",
            "2020-01-19 16:42:23 (45.4 MB/s) - ‘UCF101.rar’ saved [6932971618/6932971618]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnkFX4xyrXew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! unrar e /content/UCF101.rar /content/UCF/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j9rfGxgbGKf",
        "colab_type": "code",
        "outputId": "9b6829d2-1493-4671-8fc7-948a28d0ac3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import models, layers\n",
        "\n",
        "%matplotlib inline\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPnSOchYI6jL",
        "colab_type": "code",
        "outputId": "b1c47f6b-18c4-4534-c895-4dc84ddcd842",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = layers.Input(shape=(2, 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.framework.ops.Tensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCLiKK8GeDOF",
        "colab_type": "code",
        "outputId": "ae7faacb-66f0-4a0c-d237-d1303eda358e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "Conv_64_4_2 = layers.Conv2D(filters=64, kernel_size=(4, 4), strides=(2, 2))\n",
        "Conv_64_3_1 = layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1))\n",
        "Conv_128_4_2 = layers.Conv2D(filters=128, kernel_size=(4, 4), strides=(2, 2))\n",
        "Conv_128_3_1 = layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1))\n",
        "Conv_256_4_2 = layers.Conv2D(filters=256, kernel_size=(4, 4), strides=(2, 2))\n",
        "Conv_256_3_1 = layers.Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1))\n",
        "Conv_512_4_2 = layers.Conv2D(filters=512, kernel_size=(4, 4), strides=(2, 2))\n",
        "\n",
        "pad_zeros_1 = lambda x: layers.ZeroPadding2D(padding=1)(x)\n",
        "pad_zeros = lambda x: layers.ZeroPadding3D(padding=(0, 1, 1))(x)\n",
        "vid_disc_layer = lambda filters: layers.Conv3D(filters=filters, kernel_size=4, strides=(1, 2, 2))\n",
        "\n",
        "def shortcut(x, filters):\n",
        "    x = layers.AveragePooling2D(pool_size=(2, 2))(x)\n",
        "    x = layers.Conv2D(filters=filters, kernel_size=1, strides=1)(x)\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLBaqHMWdEKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss function\n",
        "def vid_disc_loss(y_true, y_pred):\n",
        "    return K.mean(-K.log(y_true) - K.log(1 - y_pred))\n",
        "\n",
        "def img_disc_loss(y_true, y_pred):\n",
        "    return K.mean(1/(T-2) * K.sum(-K.log(y_true) - K.log(1 - y_pred)))\n",
        "\n",
        "def g_loss(vid_pred, img_pred):\n",
        "    return K.mean(-K.log(vid_pred) - 1/(T-2) * K.sum(K.log(img_pred)))\n",
        "\n",
        "\n",
        "def get_img_enc(shape):\n",
        "    X_in = layers.Input(shape=shape)\n",
        "    L1 = Conv_64_4_2(pad_zeros_1(X_in))\n",
        "    L2 = Conv_64_3_1(pad_zeros_1(L1))\n",
        "    L3 = Conv_128_4_2(pad_zeros_1(L2))\n",
        "    L4 = Conv_128_3_1(pad_zeros_1(L3))\n",
        "    L5 = Conv_256_4_2(pad_zeros_1(L4))\n",
        "    L6 = Conv_256_3_1(pad_zeros_1(L5))\n",
        "    L7 = Conv_64_3_1(pad_zeros_1(L6))\n",
        "\n",
        "    return models.Model(inputs=X_in, outputs=L7)\n",
        "\n",
        "\n",
        "def get_video_gen(shape, mode='rgb'):\n",
        "    \"\"\"\n",
        "    mode: color mode of training\n",
        "            possible values: rgb, gray\n",
        "    \"\"\"\n",
        "    TConv_256_3_1 = layers.TransposedConv3D(filters=256, kernel_size=3, strides=1)\n",
        "    X_in = layers.Input(shape=shape)\n",
        "    L1 = TConv_256_3_1(pad_zeros_1(X_in))\n",
        "    L2 = TConv_256_3_1(pad_zeros_1(L1))\n",
        "    L3 = TransposedConv3D(filters=128, kernel_size=(3, 4, 4), strides=(1, 2, 2))(pad_zeros_1(L2))\n",
        "    L4 = TransposedConv3D(filters=128, kernel_size=3, strides=1)(pad_zeros_1(L3))\n",
        "    L5 = TransposedConv3D(filters=64, kernel_size=(3, 4, 4), strides=(1, 2, 2))(pad_zeros_1(L4))\n",
        "    L6 = TransposedConv3D(filters=64, kernel_size=3, strides=1)(pad_zeros_1(L5))\n",
        "    \n",
        "    if mode == 'rgb':\n",
        "        filters = 3\n",
        "    elif mode == 'gray':\n",
        "        filters = 1\n",
        "    else:\n",
        "        raise\n",
        "    \n",
        "    L7 = TransposedConv3D(filters=filters, kernel_size=(3, 4, 4), strides=(1, 2, 2))(pad_zeros_1(L6))\n",
        "\n",
        "    model = models.Model(inputs=X_in, outputs=L7)\n",
        "    model.compile(optimizer='adam', loss=g_loss)\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_video_disc(shape):\n",
        "    X_in = layers.Input(shape=shape)\n",
        "    L1 = vid_disc_layer(64)(pad_zeros(X_in))\n",
        "    L2 = vid_disc_layer(128)(pad_zeros(L1))\n",
        "    L3 = vid_disc_layer(256)(pad_zeros(L2))\n",
        "    L4 = vid_disc_layer(512)(pad_zeros(L3))\n",
        "    L5 = layers.Flatten()(L4)\n",
        "    L5 = layers.Dense(1, activation='sigmoid')(L5)\n",
        "\n",
        "    model = models.Model(inputs=X_in, outputs=L5)\n",
        "    model.compile(optimizer='adam', loss=vid_disc_loss)\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_img_disc(shape):\n",
        "    X_in = layers.Input(shape=shape)\n",
        "    L1 = layers.Conv2D(filters=shape[-1], kernel_size=3, strides=1)(pad_zeros_1(X_in))\n",
        "    L2 = Conv_64_4_2(pad_zeros_1(L1)) + shortcut(X_in, 64)\n",
        "    L3 = Conv_64_3_1(pad_zeros_1(L2))\n",
        "    L4 = Conv_128_4_2(pad_zeros_1(L3)) + shortcut(X_in, 128)\n",
        "    L5 = Conv_128_3_1(pad_zeros_1(L4))\n",
        "    L6 = Conv_256_4_2(pad_zeros_1(L5)) + shortcut(X_in, 256)\n",
        "    L7 = Conv_256_3_1(pad_zeros_1(L6))\n",
        "    L8 = Conv_512_4_2(pad_zeros_1(L7)) + shortcut(X_in, 512)\n",
        "    L9 = layers.Flatten()(L8)\n",
        "    L9 = layers.Dense(1, activation='sigmoid')(L9)\n",
        "\n",
        "    model = models.Model(inputs=X_in, outputs=L9)\n",
        "    model.compile(optimizer='adam', loss=img_disc_loss)\n",
        "    return model\n",
        "\n",
        "\n",
        "def LRG_block(noise, start_enc, end_enc, z_in, T, block_no):\n",
        "    C = 64\n",
        "    H, W = map(lambda x: x.value, start.shape[:-1])\n",
        "\n",
        "    if block_no in [1, 9, 17]:\n",
        "        start_enc = layers.UpSampling2D(size=2)(start_enc)\n",
        "        end_enc = layers.UpSampling2D(size=2)(end_enc)\n",
        "\n",
        "    u = layers.Dense(T * C)(noise) # because C = 64\n",
        "    u = layers.Reshape((T, C))(u)\n",
        "\n",
        "    # gating operations\n",
        "    gs = layers.Conv2D(filters=C, kernel_size=3, activation='sigmoid')(u)\n",
        "    ge = layers.Conv2D(filters=C, kernel_size=3, activation='sigmoid')(u)\n",
        "\n",
        "    # broadcasting tensors\n",
        "    def broadcast_g(tensor):\n",
        "        tensor = K.expand_dims(tensor, axis=1)\n",
        "        tensor = K.repeat_elements(tensor, W, axis=1)\n",
        "        tensor = K.expand_dims(tensor, axis=1)\n",
        "        tensor = K.repeat_elements(tensor, H, axis=1)\n",
        "        return tensor\n",
        "    \n",
        "    def broadcast_e(tensor):\n",
        "        tensor = K.expand_dims(tensor, axis=0)\n",
        "        tensor = K.repeat_elements(tensor, T, axis=0)\n",
        "        return tensor\n",
        "    \n",
        "    gs = broadcast_g(gs)\n",
        "    ge = broadcast_g(ge)\n",
        "\n",
        "    E_s = broadcast_e(start_enc)\n",
        "    E_e = broadcast_e(end_enc)\n",
        "\n",
        "    # secondary noise\n",
        "    n = layers.Conv2D(filters=C, kernel_size=3)(u)\n",
        "    n = broadcast_g(n)\n",
        "\n",
        "    # part 1 of the output\n",
        "    z_in_2 = K.Multiply([gs, E_s]) + K.Multiply([ge, E_e]) + (K.maximum(0, 1 - gs - ge) * z_in) + n\n",
        "\n",
        "    # part 2 of the output\n",
        "    part1 = layers.LeakyReLU(0.2)(layers.Conv3D(filters=C, kernel_size=3)(z_in_2))\n",
        "    part2 = layers.Conv3D(filters=C, kernel_size=3)(part1) + z_in_2\n",
        "    z_out = layers.LeakyReLU(0.2)(part2)\n",
        "    \n",
        "    return z_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR4yFVp69-Gu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating the final model\n",
        "def get_final_model(shape, img_enc_model, vid_gen_model, vid_dsc_model, img_disc_model):\n",
        "    start_frame = layers.Input(shape=shape)\n",
        "    end_frame = layers.Input(shape=shape)\n",
        "\n",
        "    # get encodings of start and end frames\n",
        "    x_s = img_enc_model(start_frame)\n",
        "    x_e = img_enc_model(end_frame)\n",
        "\n",
        "    # coarse to fine encoding generation\n",
        "    T = 4\n",
        "    z_prev = K.concatenate([x_s, x_e], axis=-1)\n",
        "    for l in range(1, 25):\n",
        "        if l % 8 == 0:\n",
        "            T *= 2\n",
        "        \n",
        "        noise_input = np.random.normal(size=(128, 1))\n",
        "        noise_input = K.cast(noise_input, dtype=\"float32\")\n",
        "\n",
        "        z_new = LRG_block(noise_input, x_s, x_e, z_prev, T, l)\n",
        "    \n",
        "    # generate video sequence\n",
        "    vid_shape = (T,) + shape\n",
        "    vid_seq = vid_gen_model(z_new)\n",
        "\n",
        "    # feed sequence to discriminator\n",
        "    vid_disc_model.trainable = False\n",
        "    vid_predictions = vid_disc_model(vid_seq)\n",
        "\n",
        "    # build the model\n",
        "    model = models.Model(inputs=[start_frame, end_frame], outputs=vid_predictions)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_054q0Mz1FvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vid_disc = get_video_disc()\n",
        "def training(epochs=100, batch_size=128):\n",
        "    # loading the data\n",
        "\n",
        "    # Creating the GAN\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch: {epoch}\")\n",
        "\n",
        "        # generate random noise\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HAEDoRZuul-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import os\n",
        "# from google.colab import files\n",
        "# files.download('/content/UCF/'+os.listdir('UCF')[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDAPGf9pfndk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from torch import cuda, nn, optim\n",
        "# class ImageEncoder(nn.Module):\n",
        "#     def __init__(self, input_shape, *args, **kwargs):\n",
        "#         super(ImageEncoder, self).__init__(*args, **kwargs)\n",
        "\n",
        "#         self.Conv_channels_64_4_2_1 = nn.Conv2d(in_channels=input_shape[0], out_channels=64, kernel_size=(4, 4), stride=2, padding=1)\n",
        "#         self.Conv_64_64_3_1_1 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), stride=1, padding=1)\n",
        "#         self.Conv_64_128"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}